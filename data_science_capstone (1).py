# -*- coding: utf-8 -*-
"""Data_Science_Capstone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCJB8u9Ec2duES-MRczSTwoMUKEjy-Nd

# **Project Description**

In the fast-paced and highly competitive world of professional basketball, success is based upon a multitude of factors, from individual player performance to team dynamics. Some of these factors, like True Shooting Percentage (TS%) is a critical metric that offers insights into a player's efficiency of scoring points. You can think of true shooting percentage as assessing how well a player performs any time one of his possessions ends in a shot attempt. TS% considers not just field goals, but also free throws and three-pointers, providing a comprehensive measure of a player's offensive contribution. The problem at hand revolves around predicting Player’s TS% for the upcoming season, a task that holds significant implications for team management and strategy. Every year there is a chance to make the team better and TS% is one of those advanced metrics where it can impact your team’s chances of winning. A team can get a steal in trades, roster rotations, and free agency if they can accurately look at a player’s TS%. There is a huge importance of accurately depicting a player’s TS%. One thing about TS% is that it serves as a key indicator of offensive prowess, directly impacting a team's ability to outscore opponents and secure victories on the court. In essence, the ability to predict TS% empowers teams to optimize their offensive strategies and enhance their chances of success in the highly competitive NBA environment.
The data analytics problem that I am analyzing is focused on leveraging historical NBA player statistics and advanced metrics to predict True Shooting Percentage for the upcoming season. There are a lot of metrics out there that are important, but in terms of evaluating a player’s offensive ability to score the ball, I think TS% takes the lead. The goal is to provide valuable insights for NBA teams seeking to optimize their rosters and elevate their competitive edge. With the accurate TS% predictions from the Machine learning model, it can help teams identify players poised to make significant offensive contributions, enabling them to make informed decisions that align with their strategic objectives and increase their chances of success on the court. This is a key metric in evaluating players’ performance. It will help the organization compare players’ strengths and weaknesses and truly assess if the player is hurting or helping the team succeed on the court.

# **Data Ingestion**
"""

#import packages

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import pandas as pd

fp = "/content/drive/MyDrive/NBA Stats 202223 All Stats  NBA Player Props Tool.csv"
df = pd.read_csv(fp)

# Drop the 'Rank' column
df = df.drop(['RANK'],axis=1)

#See if data got loaded properly

df.head()

#Confirm end of data loaded properly

df.tail()

#Get info about dataset

df.info()

#find nulls in dataset

df.isnull().sum()

rows_with_null = df[df['ORtg'].isnull() | df['DRtg'].isnull()]
rows_with_null

#The player's below dont have an ORtg or a DRtg due to their lack of Games played and MPG. ORtg and DRtg is based off per 100 posessions.
#Therefore, these stats can stay for now.

#Find different Descriptive statistics about the data.
df.describe()

"""#**Visualizing The Dataset**"""

#Here we want to check the distribution of our numerical columns
#This gives us more insights about how the data is skewed per column
columns = list(df)[:29]

df[columns].hist(figsize=(12,50),layout=(14,4))

plt.show()

#Now lets visualize the players position and see the most positions in the NBA and the least

df["POS"].value_counts().plot(kind='pie',ylabel='frequency',autopct='%1.1f%%')

#Now lets visualize the names of each of NBA player's
from wordcloud import WordCloud

# Combine all names into a single string
all_names = ' '.join(df['NAME'])

# Generate the word cloud
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_names)

# Plotting
plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Word Cloud of Names')
plt.axis('off')  # Turn off axis
plt.show()

#Now lets look at the count of player's per each team

df['TEAM'].value_counts().plot(kind='bar',ylabel='Player Counts')

#Now lets look at the correlation between the variables in the dataset
df_numerical = df.select_dtypes(include=[np.number])
df_numerical.corr()

#Now lets visualize this in a heatmap

plt.subplots(figsize=(20,14))

sns.heatmap(df_numerical.corr().abs(),vmax=1,square=True,annot=True,cmap='viridis')

plt.title("Correlation bewtween NBA 2022-2023 Season Data")

plt.show()

"""# **Further Visualization Research**
Based off the correlation between some fields and TS% I want to compare the two visually to further research the relationship
"""

#create a lineplt

sns.lineplot(data=df, x='ORtg', y='TS%')

# Add labels and title
plt.xlabel('ORtg')
plt.ylabel('TS%')
plt.title('Relationship between TS% & ORtg')

# Show the plot
plt.show()

#create a lineplt

sns.lineplot(data=df, x='eFG%', y='TS%')

# Add labels and title
plt.xlabel('eFG%')
plt.ylabel('TS%')
plt.title('Relationship between TS% & eFG%')

# Show the plot
plt.show()

#create a lineplt

sns.lineplot(data=df, x='USG%', y='TS%')

# Add labels and title
plt.xlabel('USG%')
plt.ylabel('TS%')
plt.title('Relationship between TS% & USG%')

# Show the plot
plt.show()

#create a lineplt

sns.lineplot(data=df, x='MPG', y='TS%')

# Add labels and title
plt.xlabel('MPG')
plt.ylabel('TS%')
plt.title('Relationship between TS% & MPG')

# Show the plot
plt.show()

"""# **Data Preprocessing**"""

#Check Data Types

df.dtypes

#Lets replace our Null values with zero in this case it will be okay, because 0 will be representing a record with no data.
#In the case of ORtg and DRtg, this is based off of 100 possesions, this mean a player was not able to get 100 possesions in the 2022-2023 season
df['ORtg'].fillna(0, inplace=True)
df['DRtg'].fillna(0, inplace=True)
df['TS%'].fillna(0, inplace=True)
df['eFG%'].fillna(0, inplace=True)
df['TO%'].fillna(0, inplace=True)

# There are a couple Null values but we must see if we wan to keep them or replace and delete them moving forward

df.isnull().sum()

"""# **Splitting X and y**"""

X = df[['ORtg','USG%','MPG','eFG%']]
X

#Splitting y
#y is our prediction variable we want
#In this case we want to predict True Shooting Percentage for next seson

y = df['TS%']

y

"""# **Train/Test/Split**"""

#import train_test_split from scikit learn
from sklearn.model_selection import train_test_split

#Now we need to split out train & test data

X_train,X_test,y_train,y_test =train_test_split(X,y, train_size=0.20,random_state=42)

"""# **Data Model (Linear Regression)**"""

#import Linear Refression model from scikit learn
from sklearn.linear_model import LinearRegression

#Modeling
lr = LinearRegression()
lr.fit(X_train,y_train)

#Predictions
y_pred = lr.predict(X_test)

#Adding Name Column to the testing dataset for post-processing

X_test_with_names = df.loc[X_test.index, ['NAME']].copy()

#Adding  Team Name Column to the testing dataset for post-processing

X_test_with_team = df.loc[X_test.index, ['TEAM']].copy()

#Creating a DataFrame with player names and predicted TS% from the Linear regression model

 predictions_df = pd.DataFrame({'Player Name': X_test_with_names['NAME'],'Team':X_test_with_team['TEAM'], 'Predicted TS%':y_pred})

predictions_df ['22_23_TS%'] = df.loc[X_test.index,'TS%'].values

predictions_df ['PPG'] = df.loc[X_test.index, 'PPG']

predictions_df ['MPG'] = df.loc[X_test.index, 'MPG']

predictions_df['Predicted TS%'] = round(predictions_df['Predicted TS%'],ndigits=2)

predictions_df['22_23_TS%'] = round(predictions_df['22_23_TS%'],ndigits=2)

#Displaying DataFrame
predictions_df

#Create a scatter plot that shows the relationship with a best fit line between 22_23_TS% Vs Predicted TS%

sns.set(style="whitegrid")

#Scatter plot comparing previous season vs predicted seasons TS%
plt.figure(figsize=(10,6))
sns.scatterplot(x='22_23_TS%', y='Predicted TS%', data=predictions_df, color='blue',alpha= 0.7)

#Adding Line of best fit
plt.plot([min(predictions_df['22_23_TS%']), max(predictions_df['22_23_TS%'])],
         [min(predictions_df['22_23_TS%']), max(predictions_df['22_23_TS%'])],
         color='red', linestyle='--', linewidth=2)

plt.xlabel('22-23 Season TS%')
plt.ylabel('Predicted TS%')
plt.title('22-23 season TS% vs. Predicted TS%')

plt.show()

#plot actual vs predicted
#Here we are comparing the test data set(Which is the correct data and labels) and the prediction dataset

c = [i for i in range (1,len(y_test)+1,1)]

plt.plot(c,y_test,color='r',linestyle='-')
plt.plot(c,y_pred,color='b',linestyle='-')
plt.xlabel('Scores')
plt.ylabel('index')
plt.title('Prediction')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Our prediction data is in blue
#Our historical or training set is in red

#plotting the error
#Here we are plotting the errorr values that were in the predicted set
c = [i for i in range(1,len(y_test)+1,1)]
plt.plot(c,y_test-y_pred,color='green',linestyle='-')
plt.xlabel('index')
plt.ylabel('Error')
plt.title('Error Value')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Intercept and coeff of the line
print('Intercept of the model:',lr.intercept_)
print('Coefficient of the line:', lr.coef_)

#Accuracy metrics from scikit learn
from sklearn import metrics
#MAE definition:is a measure of the average size of the mistakes in a collection of predictions, without taking their direction into account
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))
#MSE: measures how close a regression line is to a set of data points.
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))
#is one of the most commonly used measures for evaluating the quality of predictions. It shows how far predictions fall from measured true values
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
print('r square :' , metrics.r2_score(y_test, y_pred))

#r-squared shows how well the data fit the regression model
#a good r-squared values is between 0.50 to 0.99
#This output is 0.92, which is amazing including if we account for MAE,MSE, and RMSE!
#But there is always room for improvement!

#Now that we know our model is accurate, lets explore 1 more thing
#With out predicted values we want to see the player's that played under 25 min with High TS% and avg 10 pts or more
#This will be indicative to strategists in coaches in trades, rotations, and free agency
df_25min = predictions_df[(predictions_df['MPG'] <= 25) & (predictions_df['PPG']>=10)]

df_25min

#Now we want to create a scatter plot to see the relationship between Predicted TS% and Minutes Per Game
sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.scatterplot(x='MPG', y='Predicted TS%', data=df_25min,color = 'blue', alpha=0.7)
sns.regplot(x='MPG', y='Predicted TS%', data=df_25min, scatter=False, color='red', label='Regression Line')

plt.xlabel('Minutes Per Game')
plt.ylabel('Predicted True Shooting Percentage (TS%)')
plt.title('Predicted TS% by Minutes Per Game')

plt.legend()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

#Make a scatter plot with Predicted TS% vs. MPG with a regression line for the top 20 players
top_20_players = df_25min.sort_values(by='Predicted TS%', ascending=False).head(20)

sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.scatterplot(x='MPG', y='Predicted TS%', data=top_20_players, hue='Player Name', alpha=0.7)

#Add player names as text labels
for index, row in top_20_players.iterrows():
    plt.text(row['MPG'], row['Predicted TS%'], row['Player Name'], fontsize=10, ha='center', rotation='horizontal', va='baseline')

#regression line
sns.regplot(x='MPG', y='Predicted TS%', data=top_20_players, scatter=False, color='red', label='Regression Line')

plt.xlabel('Minutes Per Game')
plt.ylabel('Predicted True Shooting Percentage (TS%)')
plt.title('Top 20 Players by Predicted TS%: Predicted TS% by Minutes Per Game')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',)

plt.show()

#Now we that there are some player's that really stick out in this category
#Based off of this model and analysis
#If I was a team wanting to fill my roster with effiecient offensive player's
#I would choose from the list below
top_20_players

"""# **Data Model 2 (Decision Tree)**"""

#From the dataset, get the features that you want to use including target variable
df2 = df[['NAME','ORtg','USG%','MPG','eFG%','PPG','TS%','TEAM']].copy()
df2

"""# **Split X and Y**"""

#Splitting X and Y

X = df2.drop(['NAME','TS%','TEAM'], axis =1)
X

#Target Variable

y = df2['TS%']

y

#Train_Test_Split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **Model Training**"""

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error,r2_score
#Initalize the decision tree regressor

tree_reg = DecisionTreeRegressor(random_state=42)

tree_reg.fit(X_train, y_train)

"""# **Evaluation**"""

#Making the predictions on the testing data

y_pred = tree_reg.predict(X_test)

#evaluate the model with the mean squared error method

mse = mean_squared_error(y_test, y_pred)

print("Mean Squared Error:", mse)

# Calculate R-squared
r2 = r2_score(y_test, y_pred)
print("R-squared:", r2)

#plot actual vs predicted
#Here we are comparing the test data set(Which is the correct data and labels) and the prediction dataset

c = [i for i in range (1,len(y_test)+1,1)]

plt.plot(c,y_test,color='r',linestyle='-')
plt.plot(c,y_pred,color='b',linestyle='-')
plt.xlabel('Scores')
plt.ylabel('index')
plt.title('Prediction')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Our prediction data is in blue
#Our historical or training set is in red

#plotting the error
#Here we are plotting the errorr values that were in the predicted set
c = [i for i in range(1,len(y_test)+1,1)]
plt.plot(c,y_test-y_pred,color='green',linestyle='-')
plt.xlabel('index')
plt.ylabel('Error')
plt.title('Error Value')
plt.ticklabel_format(axis="y", style="plain")
plt.show()

#Adding Name Column to the testing dataset for post-processing
X_test_with_names_2 = df2.loc[X_test.index, ['NAME']].copy()

#Adding  Team Name Column to the testing dataset for post-processing

X_test_with_team2 = df2.loc[X_test.index, ['TEAM']].copy()

#Creating a DataFrame with player names and predicted TS% for the Decision Tree model
predictions_df2 = pd.DataFrame({'Player Name': X_test_with_names_2['NAME'],'Team':X_test_with_team2['TEAM'], 'Predicted TS%':y_pred})

predictions_df2 ['22_23_TS%'] = df2.loc[X_test.index,'TS%'].values

predictions_df2 ['PPG'] = df2.loc[X_test.index, 'PPG']

predictions_df2 ['MPG'] = df2.loc[X_test.index, 'MPG']

predictions_df2['Predicted TS%'] = round(predictions_df2['Predicted TS%'],ndigits=2)

predictions_df2['22_23_TS%'] = round(predictions_df2['22_23_TS%'],ndigits=2)

#Displaying DataFrame for decision tree predictions
predictions_df2
#We can see that there is definitley a difference

#Create a scatter plot that shows the relationship with a best fit line between 22_23_TS% Vs Predicted TS%

sns.set(style="whitegrid")

#Scatter plot comparing previous season vs predicted seasons TS%
plt.figure(figsize=(10,6))
sns.scatterplot(x='22_23_TS%', y='Predicted TS%', data=predictions_df2, color='blue',alpha= 0.7)

#Adding Line of best fit
plt.plot([min(predictions_df2['22_23_TS%']), max(predictions_df2['22_23_TS%'])],
         [min(predictions_df2['22_23_TS%']), max(predictions_df2['22_23_TS%'])],
         color='red', linestyle='--', linewidth=2)

plt.xlabel('22-23 Season TS%')
plt.ylabel('Predicted TS%')
plt.title('22-23 season TS% vs. Predicted TS%')

plt.show()

#We will check the same data as we did for the linear regression to see if our prospects changed
df_25min_2 = predictions_df2[(predictions_df2['MPG'] <= 25) & (predictions_df2['PPG']>=10)]

df_25min_2

#Now we want to create a scatter plot to see the relationship between Predicted TS% and Minutes Per Game
sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.scatterplot(x='MPG', y='Predicted TS%', data=df_25min_2,color = 'blue', alpha=0.7)
sns.regplot(x='MPG', y='Predicted TS%', data=df_25min_2, scatter=False, color='red', label='Regression Line')

plt.xlabel('Minutes Per Game')
plt.ylabel('Predicted True Shooting Percentage (TS%)')
plt.title('Predicted TS% by Minutes Per Game')

plt.legend()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

#Make a scatter plot with Predicted TS% vs. MPG with a regression line for the top 20 players
top_20_players = df_25min_2.sort_values(by='Predicted TS%', ascending=False).head(20)

sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.scatterplot(x='MPG', y='Predicted TS%', data=top_20_players, hue='Player Name', alpha=0.7)

#Add player names as text labels
for index, row in top_20_players.iterrows():
    plt.text(row['MPG'], row['Predicted TS%'], row['Player Name'], fontsize=10, ha='center', rotation='horizontal', va='baseline')

#regression line
sns.regplot(x='MPG', y='Predicted TS%', data=top_20_players, scatter=False, color='red', label='Regression Line')

plt.xlabel('Minutes Per Game')
plt.ylabel('Predicted True Shooting Percentage (TS%)')
plt.title('Top 20 Players by Predicted TS%: Predicted TS% by Minutes Per Game')

plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left',)

plt.show()

#We can notice that with this different test set it still had some of our same top prospects as in the linear regression model
top_20_players